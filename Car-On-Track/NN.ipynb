{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Neural Network\n",
    "\n",
    "In this notebook, you will train a Neural Network to drive a car around a track, using the data you collected in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os, io\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the training data\n",
    "\n",
    "The code below assume you've copied the `data.tar.gz` file into the `Car-On-Track/` folder. If you haven't done this yet, go ahead and do this! Recall: The `data.tar.gz` file was what you created in the last lab -- it contains all the training data you collected manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "def numpy_load_tar_file(f):\n",
    "    b = io.BytesIO()\n",
    "    b.write(f.read())\n",
    "    b.seek(0)\n",
    "    return np.load(b)\n",
    "\n",
    "with tarfile.open(\"data.tar.gz\", \"r\") as f:\n",
    "    x_files = []\n",
    "\n",
    "    for path in f.getnames():\n",
    "        dirname, filename = os.path.split(path)\n",
    "        if filename.startswith('X') and filename.endswith('.npy'):\n",
    "            x_files.append(path)\n",
    "\n",
    "    for x_file in x_files:\n",
    "        y_file = x_file.replace('X', 'y')\n",
    "        with f.extractfile(x_file) as fx:\n",
    "            Xs.append(numpy_load_tar_file(fx))\n",
    "        with f.extractfile(y_file) as fy:\n",
    "            ys.append(numpy_load_tar_file(fy))\n",
    "\n",
    "X = np.concatenate(Xs)\n",
    "y = np.concatenate(ys)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Spot-check Your Data\n",
    "\n",
    "The code below shows a random image (original and preprocessed). This is just to spot-check that we have read the data correctly, and that our preprocessing looks okay. You can run the code several times to see several different examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = random.randint(0, len(X)-1)\n",
    "print(rand_index)\n",
    "\n",
    "x = preprocessing.crop(X[rand_index])\n",
    "print(x.shape)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.edges(preprocessing.crop(X[rand_index]))\n",
    "print(x.shape)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess all Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val, mid_val = -45.0, 45.0, 0.0    # y.min(), y.max(), (y.min() + y.max())/2.\n",
    "print(min_val, max_val, mid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X(X):\n",
    "    X_new = []\n",
    "    for img in X:\n",
    "        img_edge, img_feats = preprocessing.preprocess(img)\n",
    "        X_new.append(img_feats)\n",
    "    return np.array(X_new)\n",
    "\n",
    "def preprocees_y(y):\n",
    "    return (y - mid_val) / (max_val - min_val)\n",
    "\n",
    "X_pcd = preprocess_X(X)\n",
    "y_pcd = preprocees_y(y)\n",
    "print(X_pcd.shape)\n",
    "print(y_pcd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Spot-check the Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15,15))\n",
    "\n",
    "for img, img_pcd, label, ax in zip(X[p], X_pcd[p], y[p], axes.flatten()):\n",
    "    img_pcd = np.array(cv2.cvtColor(img_pcd * 255.0, cv2.COLOR_GRAY2RGB), dtype=np.uint8)\n",
    "    ax.imshow(np.concatenate((img, img_pcd), axis=0))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(str(round(label, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split the data into a \"Training Set\" and a \"Test Set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pcd, y_pcd, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Augment the Data by Flipping the Frames Left-to-Right\n",
    "\n",
    "We can double the amount of training data we have using a cleaver trick! (Remember: More data is better, and this essentially gives us more data for free.)\n",
    "\n",
    "The trick is to flip each frame left-to-right (and also negate the label to match the new frame). One sample becomes two samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(X, y):\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    for img, label in zip(X, y):\n",
    "        X_new.append(img)\n",
    "        y_new.append(label)\n",
    "        X_new.append(np.fliplr(img))\n",
    "        y_new.append(-label)\n",
    "    return np.array(X_new), np.array(y_new)\n",
    "\n",
    "X_train, y_train = augment(X_train, y_train)\n",
    "X_test, y_test = augment(X_test, y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(np.concatenate((X_train[0], X_train[1]), axis=0), cv2.COLOR_GRAY2RGB))\n",
    "plt.title(\"{}   {}\".format(round(y_train[0], 2), round(y_train[1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: More Data Augmentation\n",
    "\n",
    "This time we'll augment the data using a feature from Tensorflow which will randomly shift and stretch the images to create \"synthetic\" examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Convolution2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(featurewise_center=False,\n",
    "                         samplewise_center=False,\n",
    "                         featurewise_std_normalization=False,\n",
    "                         samplewise_std_normalization=False,\n",
    "                         zca_whitening=False,\n",
    "                         rotation_range=5.0,\n",
    "                         width_shift_range=0.05,\n",
    "                         height_shift_range=0.05,\n",
    "                         shear_range=0.0,\n",
    "                         zoom_range=0.05,\n",
    "                         channel_shift_range=0.0,\n",
    "                         fill_mode='constant',\n",
    "                         cval=0.0,\n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip=False,\n",
    "                         rescale=None,\n",
    "                         preprocessing_function=None)\n",
    "\n",
    "fig, axes = plt.subplots(8, 4, figsize=(15, 15))\n",
    "\n",
    "for X_batch, y_batch in gen.flow(X_train, y_train, batch_size=len(axes.flatten())):\n",
    "    for img, label, ax in zip(X_batch, y_batch, axes.flatten()):\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2BGR))\n",
    "        ax.axis('off')\n",
    "        ax.set_title(str(round(label, 2)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Setup and Train a Convolutional Neural Network\n",
    "\n",
    "Our network will have five layers:\n",
    "- three convolutional layers (each followed by max-pooling),\n",
    "- two fully connected layers (the first using dropout).\n",
    "\n",
    "**NOTE:** This step will take several hours to run if you have a reasonable amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Input(shape=X_train.shape[1:], name='img_in')\n",
    "angle_in = Input(shape=(1,), name='angle_in')\n",
    "\n",
    "x = Convolution2D(4, (3, 3))(img_in)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(8, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "\n",
    "x = Convolution2D(16, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "\n",
    "merged = Flatten()(x)\n",
    "\n",
    "x = Dense(16)(merged)\n",
    "x = Activation('linear')(x)\n",
    "x = Dropout(.2)(x)\n",
    "\n",
    "angle_out = Dense(1, name='angle_out')(x)\n",
    "\n",
    "model = Model(inputs=[img_in], outputs=[angle_out])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = 'model_02.hdf5'\n",
    "\n",
    "save_best = callbacks.ModelCheckpoint(save_path, monitor='val_loss', verbose=2,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10,\n",
    "                                     verbose=2)\n",
    "\n",
    "callbacks_list = [save_best, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model.fit(gen.flow(X_train, y_train, batch_size=batch_size),\n",
    "          steps_per_epoch=len(X_train) // batch_size,\n",
    "          epochs=500,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_list,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Load the Network from File & Spot-check It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_02.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code below prints 25 random samples, using the NN to predict the steering angle, and also showing what the \"correct\" steering angle is.** This is useful to \"spot-check\" the performance. To see performance over the _entire_ test set, you can see the log above in the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(X_test))\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15,10))\n",
    "\n",
    "for img, label, ax in zip(X_test[p], y_test[p], axes.flatten()):\n",
    "    pred = round(model.predict(np.expand_dims(img, axis=0))[0][0], 2)\n",
    "    ax.imshow(np.squeeze(img))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(str(round(label, 2)) + \"     \" + str(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code below prints the 25 _worst_ predictions by the NN.** This is useful to diagnose situation where the NN will do poorly. It is also nice to expose samples in your data which are _mislabeled_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)[:,0]\n",
    "errors = np.abs(predictions - y_test)\n",
    "indexes = np.argsort(errors)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15,10))\n",
    "\n",
    "for index, ax in zip(indexes[::-1], axes.flatten()):\n",
    "    img = X_test[index]\n",
    "    label = y_test[index]\n",
    "    pred = predictions[index]\n",
    "    ax.imshow(np.squeeze(img))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(str(round(label, 2)) + \"     \" + str(round(pred, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
